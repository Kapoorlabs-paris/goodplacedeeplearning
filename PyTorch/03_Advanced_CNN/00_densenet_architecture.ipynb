{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Architecture in PyTorch"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to DenseNet\n\nDenseNet (Densely Connected Convolutional Network) is an architecture where each layer is connected to every other layer in a feed-forward fashion."
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained DenseNet121\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "print(densenet)"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Components of DenseNet"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'DenseNet121 has {count_parameters(densenet) / 1e6:.1f}M parameters')"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom DenseNet Block"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    \"\"\"A dense block consisting of batch norm, relu, and convolution\"\"\"\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class DenseSequential(nn.Module):\n",
    "    \"\"\"Concatenates outputs from multiple dense blocks\"\"\"\n",
    "    def __init__(self, num_blocks, in_channels, growth_rate):\n",
    "        super(DenseSequential, self).__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(num_blocks):\n",
    "            self.blocks.append(DenseBlock(in_channels + i * growth_rate, growth_rate))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for block in self.blocks:\n",
    "            new_feature = block(torch.cat(features, 1))\n",
    "            features.append(new_feature)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "# Test the dense block\n",
    "dense_block = DenseSequential(num_blocks=4, in_channels=64, growth_rate=32)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "out = dense_block(x)\n",
    "print(f'Input shape: {x.shape}')\n",
    "print(f'Output shape: {out.shape}')"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with DenseNet"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                       std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                  download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                 download=True, transform=transform)\n",
    "\n",
    "# Use a subset for quick training\n",
    "train_dataset.data = train_dataset.data[:5000]\n",
    "train_dataset.targets = train_dataset.targets[:5000]\n",
    "test_dataset.data = test_dataset.data[:1000]\n",
    "test_dataset.targets = test_dataset.targets[:1000]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the final layer for CIFAR-10 (10 classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.densenet121(pretrained=True).to(device)\n",
    "\n",
    "# Replace the final classifier\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'Model on device: {next(model.parameters()).device}')"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct / total\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Val Acc: {val_acc:.2f}%')"
   ],
   "id": "cell-11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}